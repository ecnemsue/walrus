"use strict";(globalThis.webpackChunkwalrus_docusaurus=globalThis.webpackChunkwalrus_docusaurus||[]).push([[6507],{4817:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/WriteFlow-a5c02d29e5afa38d8ef342e961f7404c.png"},5512:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>d,frontMatter:()=>i,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"design/operations-off-chain","title":"Off-Chain Operations","description":"Detailed explanation of Walrus off-chain operations including write paths, read operations, and storage node interactions.","source":"@site/../content/design/operations-off-chain.mdx","sourceDirName":"design","slug":"/design/operations-off-chain","permalink":"/docs/design/operations-off-chain","draft":false,"unlisted":false,"editUrl":"https://github.com/MystenLabs/walrus/tree/main/docs/../content/design/operations-off-chain.mdx","tags":[],"version":"current","frontMatter":{"title":"Off-Chain Operations","description":"Detailed explanation of Walrus off-chain operations including write paths, read operations, and storage node interactions.","keywords":["walrus","off-chain operations","write paths","read operations","storage nodes","slivers","availability certificate","challenge mechanism"]},"sidebar":"designSidebar","previous":{"title":"Operations on Sui","permalink":"/docs/design/operations-sui"},"next":{"title":"Walrus Assurance and Security Properties","permalink":"/docs/design/properties"}}');var o=t(2714),r=t(8885);const i={title:"Off-Chain Operations",description:"Detailed explanation of Walrus off-chain operations including write paths, read operations, and storage node interactions.",keywords:["walrus","off-chain operations","write paths","read operations","storage nodes","slivers","availability certificate","challenge mechanism"]},a=void 0,l={},c=[{value:"Write Paths",id:"write-paths",level:2},{value:"Refresh Availability",id:"refresh-availability",level:2},{value:"Inconsistent Resource Flow",id:"inconsistent-resource-flow",level:2},{value:"Read Paths",id:"read-paths",level:2},{value:"Challenge Mechanism for Storage Attestation",id:"challenge-mechanism-for-storage-attestation",level:2}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",img:"img",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components},{Term:s}=n;return s||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Term",!0),(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.p,{children:"While Walrus operations happen off Sui, they might interact with the blockchain flows defining the\nresource life cycle."}),"\n",(0,o.jsx)(n.h2,{id:"write-paths",children:"Write Paths"}),"\n",(0,o.jsx)(n.p,{children:(0,o.jsx)(n.img,{alt:"Write paths of Walrus",src:t(4817).A+"",width:"851",height:"891"})}),"\n",(0,o.jsx)(n.p,{children:"Systems overview of writes, illustrated in the previous image:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["A ",(0,o.jsx)(s,{lookup:"User",children:"user"})," acquires a storage resource of appropriate size and duration on chain, either by directly\nbuying it on the Walrus system object or a secondary market. A ","user"," can split, merge, and\ntransfer owned storage resources."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["When users want to store a ",(0,o.jsx)(s,{lookup:"Blob",children:"blob"}),", they first erasure code it and compute the\n",(0,o.jsx)(s,{lookup:"Blob ID",children:"blob ID"}),". Then they can perform the following steps themselves, or use a ",(0,o.jsx)(s,{lookup:"Publisher",children:"publisher"})," to perform steps\non their behalf."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The ","user"," goes on chain (Sui) and updates a storage resource to register the ","blob ID"," with the\ndesired size and lifetime. This emits an event, received by ",(0,o.jsx)(s,{lookup:"Storage node",children:"storage nodes"}),". After the\n","user"," receives they then continue the upload."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The ","user"," sends the ",(0,o.jsx)(s,{lookup:"Blob metadata",children:"blob metadata"})," to all ","storage nodes"," and each of the ","blob"," slivers to the storage\nnode that currently manages the corresponding ",(0,o.jsx)(s,{lookup:"Shard",children:"shard"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["A ","storage node"," managing a ","shard"," receives a ",(0,o.jsx)(s,{lookup:"Sliver",children:"sliver"})," and checks it against the ","blob ID",".\nIt also checks that there is a ","blob"," resource with the ","blob ID"," that is authorized to store\na ","blob",". If correct, the ","storage node"," then signs a statement that it holds the ","sliver"," for ","blob ID","\n(and metadata) and returns it to the ","user","."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The ","user"," puts together the signatures returned from ","storage nodes"," into an availability certificate\nand submits it to the chain. When the certificate is verified on chain, an availability event for\nthe ","blob ID"," is emitted, and all other ","storage nodes"," seek to download any missing shards for the\n","blob ID",". This event emitted by Sui is the ",(0,o.jsx)(n.a,{href:"/docs/design/properties",children:"point of availability (PoA)"})," for the\n","blob ID","."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["After the ",(0,o.jsx)(s,{lookup:"Point of availability",children:"PoA"}),", and without ","user"," involvement, ","storage nodes"," sync and recover any missing metadata\nand slivers."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["The ","user"," waits for 2/3 of ","shard"," signatures to return to create the certificate of\navailability. The rate of the code is below 1/3, allowing for ",(0,o.jsx)(s,{lookup:"Reconstruction",children:"reconstruction"})," even if only 1/3 of\nshards return the ","sliver"," for a read. Because at most 1/3 of the ","storage nodes"," can fail, this ensures\n","reconstruction"," if a reader requests slivers from all ","storage nodes",". The full process can\nbe mediated by a ","publisher"," that receives a ","blob"," and drives the process to completion."]}),"\n",(0,o.jsx)(n.h2,{id:"refresh-availability",children:"Refresh Availability"}),"\n",(0,o.jsxs)(n.p,{children:["Because no content data is required to refresh the duration of storage, refresh is conducted fully\non chain within the protocol. To request an extension to the availability of a ","blob",", a ","user"," provides\nan appropriate storage resource. Upon success this emits an event that ","storage nodes"," receive to\nextend the time for which each ","sliver"," is stored."]}),"\n",(0,o.jsx)(n.h2,{id:"inconsistent-resource-flow",children:"Inconsistent Resource Flow"}),"\n",(0,o.jsxs)(n.p,{children:["When a correct ","storage node"," tries to reconstruct a ","sliver"," for a ","blob"," past ",(0,o.jsx)(n.a,{href:"/docs/design/properties",children:"PoA"}),",\nthis may fail if the encoding of the ","blob"," was incorrect. In this case, the ","storage node"," can instead\nextract an ",(0,o.jsx)(s,{lookup:"Inconsistency proof",children:"inconsistency proof"})," for the ","blob ID",". It then uses the proof to create an inconsistency\ncertificate and upload it on chain."]}),"\n",(0,o.jsx)(n.p,{children:"The flow is as follows:"}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["A ","storage node"," fails to reconstruct a ","sliver",", and instead computes an ","inconsistency proof","."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The ","storage node"," sends the ","blob ID"," and ","inconsistency proof"," to all ","storage nodes"," of the Walrus\nepoch. The ","storage nodes"," verify the proof and sign it."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The ","storage node"," who found the inconsistency aggregates the signatures into an inconsistency\ncertificate and sends it to the Walrus smart contract, which verifies it and emits an inconsistent\nresource event."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Upon receiving an inconsistent resource event, correct ","storage nodes"," delete ","sliver"," data for the\n","blob ID"," and record in the metadata to return ",(0,o.jsx)(n.code,{children:"None"})," for the ","blob ID"," for the\n",(0,o.jsx)(n.a,{href:"/docs/design/properties",children:"availability period"}),". No ",(0,o.jsx)(s,{lookup:"Storage attestation",children:"storage attestation"})," challenges are issued for this\n","blob ID","."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.admonition,{title:"Reading inconsistent blobs",type:"tip",children:[(0,o.jsxs)(n.p,{children:["A ","blob ID"," that is inconsistent always resolves to ",(0,o.jsx)(n.code,{children:"None"})," upon reading because\nthe read process re-encodes the received ","blob"," to check that the ","blob ID"," is correctly derived from a\nconsistent encoding. This means that an ","inconsistency proof"," reveals only a true fact to storage\nnodes (that do not otherwise run decoding), and does not change the output of read in any case."]}),(0,o.jsx)(n.p,{children:"However, partial reads leveraging the systematic nature of the encoding might successfully return\npartial reads for inconsistently encoded files. Thus, if consistency and availability of reads is\nimportant, dApps should do full reads rather than partial reads."})]}),"\n",(0,o.jsx)(n.h2,{id:"read-paths",children:"Read Paths"}),"\n",(0,o.jsxs)(n.p,{children:["A ","user"," can read stored ","blobs"," either directly or through an ",(0,o.jsx)(s,{lookup:"Aggregator",children:"aggregator"}),(0,o.jsx)(s,{lookup:"Cache",children:"cache"}),". The operations are the\nsame for direct ","user"," access, for aggregators, and caches in case of ","cache"," misses. In practice, most\nreads happen through caches for ","blobs"," that are hot and do not result in requests to ","storage nodes","."]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The reader gets the metadata for the ","blob ID"," from any ","storage node",", and authenticates it using\nthe ","blob ID","."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The reader then sends a request to the ","storage nodes"," for the shards corresponding to the ","blob ID","\nand waits for (f+1) to respond. Sufficient requests are sent in parallel to ensure low latency\nfor reads."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The reader authenticates the slivers returned with the ","blob ID",", reconstructs the ","blob",", and decides\nwhether the contents are a valid ","blob"," or inconsistent."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["Optionally, for a ","cache",", the result is cached and can be served without ","reconstruction"," until it is\nevicted from the ","cache",". Requests for the ","blob"," to the ","cache"," return the ","blob"," contents, or a proof\nthat the ","blob"," is inconsistently encoded."]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.h2,{id:"challenge-mechanism-for-storage-attestation",children:["Challenge Mechanism for ","Storage Attestation"]}),"\n",(0,o.jsxs)(n.p,{children:["During an epoch, a correct ","storage node"," challenges all shards to provide symbols for ","blob"," slivers\npast ","PoA",":"]}),"\n",(0,o.jsxs)(n.ul,{children:["\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The list of available ","blobs"," for the epoch is determined by the sequence of Sui events up\nto the past epoch. Inconsistent ","blobs"," are not challenged, and a record proving this status\ncan be returned instead."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["A challenge sequence is determined by providing a seed to the challenged ","shard",". The sequence is\nthen computed based both on the seed ",(0,o.jsx)(n.strong,{children:"and"})," the content of each challenged ","blob ID",". This creates\na sequential read dependency."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsxs)(n.p,{children:["The response to the challenge provides the sequence of ","shard"," contents for the ","blob"," IDs in a\ntimely manner."]}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"The challenger node uses thresholds to determine whether the challenge was passed, and reports\nthe result on chain."}),"\n"]}),"\n",(0,o.jsxs)(n.li,{children:["\n",(0,o.jsx)(n.p,{children:"The challenge/response communication is authenticated."}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(n.p,{children:["Challenges provide some reassurance that the ","storage node"," can actually recover ","shard"," data in a\nprobabilistic manner, avoiding ","storage nodes"," getting payment without any evidence they might\nretrieve ","shard"," data. The sequential nature of the challenge and some reasonable timeout also ensures\nthat the process is timely."]})]})}function d(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(h,{...e})}):h(e)}},8885:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>a});var s=t(9378);const o={},r=s.createContext(o);function i(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);
"use strict";(globalThis.webpackChunkwalrus_docusaurus=globalThis.webpackChunkwalrus_docusaurus||[]).push([[4804],{3489:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>d});const s=JSON.parse('{"id":"design/encoding","title":"Encoding, Overheads, and Verification","description":"Technical details of Walrus encoding using RedStuff erasure codes, data authentication, integrity checks, and consistency verification.","source":"@site/../content/design/encoding.mdx","sourceDirName":"design","slug":"/design/encoding","permalink":"/docs/design/encoding","draft":false,"unlisted":false,"editUrl":"https://github.com/MystenLabs/walrus/tree/main/docs/../content/design/encoding.mdx","tags":[],"version":"current","frontMatter":{"title":"Encoding, Overheads, and Verification","description":"Technical details of Walrus encoding using RedStuff erasure codes, data authentication, integrity checks, and consistency verification.","keywords":["walrus","encoding","erasure codes","redstuff","data integrity","authentication","consistency check","merkle tree","blob verification"]},"sidebar":"designSidebar","previous":{"title":"Basic Architecture and Security Assumptions","permalink":"/docs/design/architecture"},"next":{"title":"Operations","permalink":"/docs/design/operations"}}');var i=n(2714),a=n(8885);const r={title:"Encoding, Overheads, and Verification",description:"Technical details of Walrus encoding using RedStuff erasure codes, data authentication, integrity checks, and consistency verification.",keywords:["walrus","encoding","erasure codes","redstuff","data integrity","authentication","consistency check","merkle tree","blob verification"]},o=void 0,c={},d=[{value:"Basics",id:"basics",level:2},{value:"Metadata and Data Authentication",id:"metadata-and-data-authentication",level:2},{value:"Data Integrity and Consistency",id:"data-integrity-and-consistency",level:2},{value:"Default Consistency Check",id:"default-consistency-check",level:3},{value:"Strict Consistency Check",id:"strict-consistency-check",level:3}];function l(e){const t={a:"a",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components},{Term:s}=t;return s||function(e,t){throw new Error("Expected "+(t?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Term",!0),(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(t.p,{children:["Walrus uses a bespoke erasure-code construction (",(0,i.jsx)(s,{lookup:"RedStuff",children:"RedStuff"}),") based on efficiently computable\nReed-Solomon codes. The full details of the encoding are described in the\n",(0,i.jsx)(t.a,{target:"_blank","data-noBrokenLinkCheck":!0,href:n(5076).A+"",children:"whitepaper"}),". This page summarizes some of the basic techniques and terminology used\nby Walrus."]}),"\n",(0,i.jsx)(t.h2,{id:"basics",children:"Basics"}),"\n",(0,i.jsx)(t.p,{children:"The following list summarizes the basic encoding and cryptographic techniques used in Walrus:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["An ",(0,i.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Erasure_code",children:"erasure code"})," encode algorithm takes a ",(0,i.jsx)(s,{lookup:"Blob",children:"blob"}),",\nsplits it into a number (k) of symbols, and encodes it into (n>k) symbols in such a way that a\nsubset of these (n) symbols can be used to reconstruct the ","blob","."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Walrus uses a highly efficient erasure code and selects (k) such that a third of symbols can be\nused to reconstruct the ","blob"," by the decode algorithm."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["The encoding is ",(0,i.jsx)(t.em,{children:"systematic"}),", meaning that some ",(0,i.jsx)(s,{lookup:"Storage node",children:"storage nodes"})," hold part of the original ","blob",",\nallowing for fast random-access reads."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsx)(t.p,{children:"All encoding and decoding operations are deterministic, and encoders have no discretion about it."}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["For each ","blob",", multiple symbols are combined into a ",(0,i.jsx)(t.strong,{children:(0,i.jsx)(s,{lookup:"Sliver",children:"sliver"})}),", which is then assigned to a ",(0,i.jsx)(s,{lookup:"Shard",children:"shard"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Storage nodes"," manage one or more shards, and corresponding slivers of each ","blob"," are distributed\nto all the storage shards."]}),"\n"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["The detailed encoding setup results in an expansion of the ","blob"," size by a factor of (4.5 \\sim 5).\nThis is independent of the number of shards and the number of ","storage nodes","."]}),"\n",(0,i.jsx)(t.h2,{id:"metadata-and-data-authentication",children:"Metadata and Data Authentication"}),"\n",(0,i.jsxs)(t.p,{children:["Each ","blob"," is also associated with some metadata including a ",(0,i.jsx)(t.strong,{children:(0,i.jsx)(s,{lookup:"Blob ID",children:"blob ID"})})," to allow data authenticity\nverification:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["The ","blob ID"," is computed as an authenticator of the set of all ","shard"," data and metadata (byte size,\nencoding, ","blob"," hash)."]}),"\n",(0,i.jsxs)(t.p,{children:["Walrus hashes a ","sliver"," representation in each of the shards and adds the resulting hashes into a\nMerkle tree. Then the root of the Merkle tree is the ","blob"," hash used to derive the ","blob ID"," that\nidentifies the ","blob"," in the system."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Each ","storage node"," can use the ","blob ID"," to check if some ","shard"," data belongs to a ","blob"," using the\nauthenticated structure corresponding to the ","blob"," hash (Merkle tree). A successful check means\nthat the data is indeed as intended by the writer of the ","blob","."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"data-integrity-and-consistency",children:"Data Integrity and Consistency"}),"\n",(0,i.jsxs)(t.p,{children:["Slivers, metadata, and the ","blob ID"," are computed by the ",(0,i.jsx)(s,{lookup:"Client",children:"client"})," when writing a ","blob",". As clients are\ngenerally untrusted, any step in this computation can be incorrect, either through a bug or on\npurpose. Concretely, the ","client"," can make one or more of the following mistakes:"]}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"Incorrectly compute slivers."}),"\n",(0,i.jsxs)(t.li,{children:["Incorrectly compute the ","sliver"," hashes based on the slivers."]}),"\n",(0,i.jsxs)(t.li,{children:["Incorrectly compute the ","blob ID"," based on the ","sliver"," hashes and other metadata."]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Walrus has several mechanisms to detect each of these:"}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Inconsistencies of the last type (incorrect ","blob","-ID computation) are detected immediately by\n","storage nodes"," when the ","client"," attempts to upload metadata. ","Storage nodes"," will never issue storage\ncertificates for such ","blobs",", and they are therefore never even certified."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Inconsistencies of the second type (incorrect ","sliver","-hash computation) are generally detected\neither before or shortly after certification, unless the slivers with incorrect hashes are handled\nby malicious ","storage nodes","."]}),"\n",(0,i.jsxs)(t.p,{children:["Honest ","storage nodes"," that are assigned a ","sliver"," with an incorrect hash attempt to recover it from\nother ","storage nodes"," and then notice the inconsistency. They can then extract one symbol per ","sliver","\nto form an ",(0,i.jsx)(t.em,{children:(0,i.jsx)(s,{lookup:"Inconsistency proof",children:"inconsistency proof"})}),", which is then used to mark the ","blob"," as ",(0,i.jsx)(t.em,{children:"invalid"}),". After this,\n","storage nodes"," can delete slivers belonging to inconsistently encoded ","blobs",", and upon request\nreturn either the ","inconsistency proof"," or an ",(0,i.jsx)(s,{lookup:"Inconsistency certificate",children:"inconsistency certificate"})," posted on chain."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:["Inconsistencies of the first type can also be detected by ","storage nodes",". The process is the same\nas in the case above, but it is not guaranteed to be triggered immediately after certification."]}),"\n",(0,i.jsxs)(t.p,{children:["As a result, such inconsistencies may persist within the network for longer periods of time,\nrequiring additional ","client","-side checks."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"The following sections describe the different types of consistency checks performed by clients."}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-admonish",metastring:'info title="Select the appropriate consistency check"',children:"In the majority of cases, the default consistency check is sufficient, in particular if the writer\nof the blob is trusted. The strict consistency check is only needed if specific availability\nguarantees are required. If the writer of a blob is known and trusted, it is also possible to\ncompletely disable the consistency check.\n"})}),"\n",(0,i.jsx)(t.h3,{id:"default-consistency-check",children:"Default Consistency Check"}),"\n",(0,i.jsxs)(t.p,{children:["When reading a ","blob"," from Walrus, a ","client"," first checks the authenticity of the metadata and then\nrequests a subset of primary slivers checking their authenticity using the metadata. Using 334\nauthentic primary slivers, the original ","blob"," data can be decoded."]}),"\n",(0,i.jsxs)(t.p,{children:["The encoding used by Walrus has the property that ",(0,i.jsx)(t.em,{children:"the first 334 primary slivers contain the\n(potentially padded) unencoded data"}),". This means that the (cryptographic) hashes of these slivers\ntogether with the ","blob"," length uniquely determine the content of the ","blob",". Therefore, by recomputing\nthe ","sliver"," hashes of the first 334 slivers and checking them against the metadata, the ","client"," can\nverify that the decoded data is correct. If this check succeeds, the data is provided to the ",(0,i.jsx)(s,{lookup:"User",children:"user"}),",\notherwise an error is returned. This check provides the following guarantees:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-admonish",metastring:'tip title="Data consistency property"',children:"Any correct client attempting to read a blob, performing the default consistency check, will either\nread the specific value authenticated by the writer or return an error.\n"})}),"\n",(0,i.jsx)(t.h3,{id:"strict-consistency-check",children:"Strict Consistency Check"}),"\n",(0,i.jsxs)(t.p,{children:["If the ","blob"," was encoded correctly, any set of 334 primary slivers decode to the same data. However,\nif the writer of a ","blob"," encoded the data incorrectly, different sets of slivers may decode to\ndifferent data. Even in that case, there is only one correct value that can be read by an honest\n","client"," (guarantee stated above), but some read attempts may result in a failure while others\nsucceed. Furthermore, the ","blob"," may be detected as inconsistent by ","storage nodes"," at a later point,\nafter which all read attempts would fail."]}),"\n",(0,i.jsxs)(t.p,{children:["For this reason, Walrus optionally offers a ",(0,i.jsx)(t.em,{children:"strict consistency check"}),": After decoding the ","blob",", the\n","client"," fully ",(0,i.jsx)(t.em,{children:"re-encodes"})," it and recomputes all hashes and the ","blob ID",". Only if that computation\nresults in the ","blob ID"," they are trying to read is the read considered successful. This check is\nstrictly stronger than the default consistency check and therefore also fulfills the data\nconsistency property above."]}),"\n",(0,i.jsxs)(t.p,{children:["In addition, this process ",(0,i.jsxs)(t.em,{children:["ensures that the original writer encoded the ","blob"," correctly"]}),". Therefore,\nafter a ","blob"," was read successfully with the strict consistency check enabled, the following property\nholds in addition:"]}),"\n",(0,i.jsx)(t.p,{children:":: tip Guarantee after strict consistency check succeeded"}),"\n",(0,i.jsxs)(t.p,{children:["Any correct ","client"," attempting to read a ","blob"," during its lifetime will always succeed and read the\nsame data intended by the writer, irrespective of which consistency check is performed."]}),"\n",(0,i.jsx)(t.p,{children:":::"}),"\n",(0,i.jsx)(t.p,{children:"For quilt patches, only a variant of the default consistency check is available, as only\npart of the quilt is read."})]})}function h(e={}){const{wrapper:t}={...(0,a.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(l,{...e})}):l(e)}},5076:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/files/walrus_whitepaper_v2-31701a689e75cc47048440b56789f388.pdf"},8885:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>o});var s=n(9378);const i={},a=s.createContext(i);function r(e){const t=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:t},e.children)}}}]);